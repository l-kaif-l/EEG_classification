{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cd9410b5",
      "metadata": {
        "id": "cd9410b5"
      },
      "source": [
        "Classify EEG spectrograms into different harmful brain activities using deep learning.\n",
        "A ResNet34d model was fine-tuned for the task with 1 input channel and trained using Stratified Group KFold cross-validation.\n",
        "KL loss: 0.715760646315781. The model struggled to achieve high performance, which could be due to the complexity of the EEG signals and class imbalances."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EinfrbJC7FHV",
      "metadata": {
        "id": "EinfrbJC7FHV"
      },
      "source": [
        "pre-trained ResNet34d model (from the timm library)\n",
        "spectrograms are single-channel (grayscale), we set input channels to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8d9bf2",
      "metadata": {
        "id": "ce8d9bf2",
        "outputId": "91d973bb-b316-455c-b604-b4db65ac614b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import gc\n",
        "import copy\n",
        "import yaml\n",
        "import random\n",
        "import shutil\n",
        "from time import time\n",
        "import typing as tp\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.cuda import amp\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5edbbc6e",
      "metadata": {
        "id": "5edbbc6e"
      },
      "outputs": [],
      "source": [
        "#A list of class labels corresponding to the types of harmful brain activities\n",
        "ROOT = Path.cwd().parent\n",
        "INPUT = ROOT / \"input\"\n",
        "OUTPUT = ROOT / \"output\"\n",
        "SRC = ROOT / \"src\"\n",
        "\n",
        "DATA = INPUT / \"hms-harmful-brain-activity-classification\"\n",
        "TRAIN_SPEC = DATA / \"train_spectrograms\"\n",
        "TEST_SPEC = DATA / \"test_spectrograms\"\n",
        "\n",
        "TMP = ROOT / \"tmp\"\n",
        "TRAIN_SPEC_SPLIT = TMP / \"train_spectrograms_split\"\n",
        "TEST_SPEC_SPLIT = TMP / \"test_spectrograms_split\"\n",
        "TMP.mkdir(exist_ok=True)\n",
        "TRAIN_SPEC_SPLIT.mkdir(exist_ok=True)\n",
        "TEST_SPEC_SPLIT.mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "RANDAM_SEED = 1086\n",
        "CLASSES = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\n",
        "N_CLASSES = len(CLASSES)\n",
        "FOLDS = [0, 1, 2, 3, 4]\n",
        "N_FOLDS = len(FOLDS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cfaea44",
      "metadata": {
        "id": "2cfaea44"
      },
      "source": [
        "### Data Preparation:\n",
        "\n",
        "#####Reading & Splitting Data: Spectrograms are loaded and grouped by spectrogram_id, with the first subset of each used for faster training.\n",
        "#####Folds: Data is split into 5 folds for cross-validation.\n",
        "#####File Processing: Spectrogram files are loaded and split into smaller chunks for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b22b7f",
      "metadata": {
        "id": "97b22b7f",
        "outputId": "d42c8985-caf0-4e95-a127-053cfd2c073c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(106800, 15)\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv(DATA / \"train.csv\")\n",
        "\n",
        "# convert vote to probability\n",
        "train[CLASSES] /= train[CLASSES].sum(axis=1).values[:, None]\n",
        "\n",
        "print(train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f87fc03",
      "metadata": {
        "id": "6f87fc03",
        "outputId": "c77af34a-1416-499d-d615-7bbe85a32eeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11138, 15)\n"
          ]
        }
      ],
      "source": [
        "train = train.groupby(\"spectrogram_id\").head(1).reset_index(drop=True)\n",
        "print(train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb72283b",
      "metadata": {
        "id": "eb72283b"
      },
      "outputs": [],
      "source": [
        "# split data\n",
        "sgkf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n",
        "\n",
        "train[\"fold\"] = -1\n",
        "\n",
        "for fold_id, (_, val_idx) in enumerate(\n",
        "    sgkf.split(train, y=train[\"expert_consensus\"], groups=train[\"patient_id\"])\n",
        "):\n",
        "    train.loc[val_idx, \"fold\"] = fold_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239a182b",
      "metadata": {
        "id": "239a182b",
        "outputId": "d1b14a39-79b4-4f26-9e46-0586f25bbad0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seizure_vote</th>\n",
              "      <th>lpd_vote</th>\n",
              "      <th>gpd_vote</th>\n",
              "      <th>lrda_vote</th>\n",
              "      <th>grda_vote</th>\n",
              "      <th>other_vote</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fold</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>407.878970</td>\n",
              "      <td>240.847820</td>\n",
              "      <td>262.474513</td>\n",
              "      <td>142.304068</td>\n",
              "      <td>286.407590</td>\n",
              "      <td>800.087038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360.427388</td>\n",
              "      <td>231.931854</td>\n",
              "      <td>193.738000</td>\n",
              "      <td>173.763906</td>\n",
              "      <td>333.566517</td>\n",
              "      <td>1166.572336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>441.934721</td>\n",
              "      <td>328.255479</td>\n",
              "      <td>237.291923</td>\n",
              "      <td>163.192668</td>\n",
              "      <td>355.493987</td>\n",
              "      <td>926.831222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>425.685980</td>\n",
              "      <td>195.568155</td>\n",
              "      <td>182.017264</td>\n",
              "      <td>148.850582</td>\n",
              "      <td>259.828026</td>\n",
              "      <td>864.049993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>392.391708</td>\n",
              "      <td>234.916737</td>\n",
              "      <td>120.355588</td>\n",
              "      <td>129.112045</td>\n",
              "      <td>258.598367</td>\n",
              "      <td>873.625556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      seizure_vote    lpd_vote    gpd_vote   lrda_vote   grda_vote  \\\n",
              "fold                                                                 \n",
              "0       407.878970  240.847820  262.474513  142.304068  286.407590   \n",
              "1       360.427388  231.931854  193.738000  173.763906  333.566517   \n",
              "2       441.934721  328.255479  237.291923  163.192668  355.493987   \n",
              "3       425.685980  195.568155  182.017264  148.850582  259.828026   \n",
              "4       392.391708  234.916737  120.355588  129.112045  258.598367   \n",
              "\n",
              "       other_vote  \n",
              "fold               \n",
              "0      800.087038  \n",
              "1     1166.572336  \n",
              "2      926.831222  \n",
              "3      864.049993  \n",
              "4      873.625556  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.groupby(\"fold\")[CLASSES].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32d57b47",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2e4d021b167942deacb193787ec87135"
          ]
        },
        "id": "32d57b47",
        "outputId": "bdb42520-8667-4f8d-c5ed-e84a2cf676f5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e4d021b167942deacb193787ec87135",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/11138 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# split spectogram files\n",
        "for spec_id, df in tqdm(train.groupby(\"spectrogram_id\")):\n",
        "    spec = pd.read_parquet(TRAIN_SPEC / f\"{spec_id}.parquet\")\n",
        "\n",
        "    spec_arr = spec.fillna(0).values[:, 1:].T.astype(\"float32\")  # (Hz, Time) = (400, 300)\n",
        "\n",
        "    for spec_offset, label_id in df[\n",
        "        [\"spectrogram_label_offset_seconds\", \"label_id\"]\n",
        "    ].astype(int).values:\n",
        "        spec_offset = spec_offset // 2\n",
        "        split_spec_arr = spec_arr[:, spec_offset: spec_offset + 300]\n",
        "        np.save(TRAIN_SPEC_SPLIT / f\"{label_id}.npy\" , split_spec_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e79551e",
      "metadata": {
        "id": "1e79551e"
      },
      "source": [
        "###Model Definition:\n",
        "\n",
        "#####Custom class HMSHBACSpecModel defines the model architecture, using a pre-trained backbone (ResNet34d) with a custom classifier head.\n",
        "#####HMSHBACSpecDataset class handles loading and transforming the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5d98cb0",
      "metadata": {
        "id": "e5d98cb0"
      },
      "outputs": [],
      "source": [
        "class HMSHBACSpecModel(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            model_name: str,\n",
        "            pretrained: bool,\n",
        "            in_channels: int,\n",
        "            num_classes: int,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(\n",
        "            model_name=model_name, pretrained=pretrained,\n",
        "            num_classes=num_classes, in_chans=in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.model(x)\n",
        "\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "836e5091",
      "metadata": {
        "id": "836e5091"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "FilePath = tp.Union[str, Path]\n",
        "Label = tp.Union[int, float, np.ndarray]\n",
        "\n",
        "class HMSHBACSpecDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_paths: tp.Sequence[FilePath],\n",
        "        labels: tp.Sequence[Label],\n",
        "        transform: A.Compose,\n",
        "    ):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        img_path = self.image_paths[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        img = np.load(img_path)  # shape: (Hz, Time) = (400, 300)\n",
        "\n",
        "        # log transform\n",
        "        img = np.clip(img,np.exp(-4), np.exp(8))\n",
        "        img = np.log(img)\n",
        "\n",
        "        # normalize per image\n",
        "        eps = 1e-6\n",
        "        img_mean = img.mean(axis=(0, 1))\n",
        "        img = img - img_mean\n",
        "        img_std = img.std(axis=(0, 1))\n",
        "        img = img / (img_std + eps)\n",
        "\n",
        "        img = img[..., None] # shape: (Hz, Time) -> (Hz, Time, Channel)\n",
        "        img = self._apply_transform(img)\n",
        "\n",
        "        return {\"data\": img, \"target\": label}\n",
        "\n",
        "    def _apply_transform(self, img: np.ndarray):\n",
        "        \"\"\"apply transform to image and mask\"\"\"\n",
        "        transformed = self.transform(image=img)\n",
        "        img = transformed[\"image\"]\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e116f4fe",
      "metadata": {
        "id": "e116f4fe"
      },
      "source": [
        "Evaluation:\n",
        "\n",
        "KL Divergence loss is used for validation, with metrics computed at the end of each epoch.\n",
        "The best model based on validation loss is saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed59ced7",
      "metadata": {
        "id": "ed59ced7"
      },
      "outputs": [],
      "source": [
        "class KLDivLossWithLogits(nn.KLDivLoss):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(reduction=\"batchmean\")\n",
        "\n",
        "    def forward(self, y, t):\n",
        "        y = nn.functional.log_softmax(y,  dim=1)\n",
        "        loss = super().forward(y, t)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class KLDivLossWithLogitsForVal(nn.KLDivLoss):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\"\"\"\n",
        "        super().__init__(reduction=\"batchmean\")\n",
        "        self.log_prob_list  = []\n",
        "        self.label_list = []\n",
        "\n",
        "    def forward(self, y, t):\n",
        "        y = nn.functional.log_softmax(y, dim=1)\n",
        "        self.log_prob_list.append(y.numpy())\n",
        "        self.label_list.append(t.numpy())\n",
        "\n",
        "    def compute(self):\n",
        "        log_prob = np.concatenate(self.log_prob_list, axis=0)\n",
        "        label = np.concatenate(self.label_list, axis=0)\n",
        "        final_metric = super().forward(\n",
        "            torch.from_numpy(log_prob),\n",
        "            torch.from_numpy(label)\n",
        "        ).item()\n",
        "        self.log_prob_list = []\n",
        "        self.label_list = []\n",
        "\n",
        "        return final_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ebda63d",
      "metadata": {
        "id": "0ebda63d"
      },
      "source": [
        "###Training Loop:\n",
        "\n",
        "#####Random seed is set for reproducibility.\n",
        "#####Model, optimizer, and scheduler are initialized.\n",
        "#####Mixed-precision training with torch.cuda.amp is used for faster training.\n",
        "#####Training and validation loops are implemented, with model checkpoints saved if validation loss improves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfe36438",
      "metadata": {
        "id": "bfe36438"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    model_name = \"resnet34d\"\n",
        "    img_size = 512\n",
        "    max_epoch = 9\n",
        "    batch_size = 32\n",
        "    lr = 1.0e-03\n",
        "    weight_decay = 1.0e-02\n",
        "    es_patience =  5\n",
        "    seed = 1086\n",
        "    deterministic = True\n",
        "    enable_amp = True\n",
        "    device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37c652d",
      "metadata": {
        "id": "b37c652d"
      },
      "outputs": [],
      "source": [
        "def get_path_label(val_fold, train_all: pd.DataFrame):\n",
        "    \"\"\"Get file path and target info.\"\"\"\n",
        "\n",
        "    train_idx = train_all[train_all[\"fold\"] != val_fold].index.values\n",
        "    val_idx   = train_all[train_all[\"fold\"] == val_fold].index.values\n",
        "    img_paths = []\n",
        "    labels = train_all[CLASSES].values\n",
        "    for label_id in train_all[\"label_id\"].values:\n",
        "        img_path = TRAIN_SPEC_SPLIT / f\"{label_id}.npy\"\n",
        "        img_paths.append(img_path)\n",
        "\n",
        "    train_data = {\n",
        "        \"image_paths\": [img_paths[idx] for idx in train_idx],\n",
        "        \"labels\": [labels[idx].astype(\"float32\") for idx in train_idx]}\n",
        "\n",
        "    val_data = {\n",
        "        \"image_paths\": [img_paths[idx] for idx in val_idx],\n",
        "        \"labels\": [labels[idx].astype(\"float32\") for idx in val_idx]}\n",
        "\n",
        "    return train_data, val_data, train_idx, val_idx\n",
        "\n",
        "\n",
        "def get_transforms(CFG):\n",
        "    train_transform = A.Compose([\n",
        "        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n",
        "        ToTensorV2(p=1.0)\n",
        "    ])\n",
        "    val_transform = A.Compose([\n",
        "        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n",
        "        ToTensorV2(p=1.0)\n",
        "    ])\n",
        "    return train_transform, val_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a26243",
      "metadata": {
        "id": "26a26243"
      },
      "outputs": [],
      "source": [
        "def train_one_fold(CFG, val_fold, train_all, output_path):\n",
        "    \"\"\"Main\"\"\"\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    set_random_seed(CFG.seed, deterministic=CFG.deterministic)\n",
        "    device = torch.device(CFG.device)\n",
        "\n",
        "    train_path_label, val_path_label, _, _ = get_path_label(val_fold, train_all)\n",
        "    train_transform, val_transform = get_transforms(CFG)\n",
        "\n",
        "    train_dataset = HMSHBACSpecDataset(**train_path_label, transform=train_transform)\n",
        "    val_dataset = HMSHBACSpecDataset(**val_path_label, transform=val_transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
        "\n",
        "    model = HMSHBACSpecModel(\n",
        "        model_name=CFG.model_name, pretrained=True, num_classes=6, in_channels=1)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "    scheduler = lr_scheduler.OneCycleLR(\n",
        "        optimizer=optimizer, epochs=CFG.max_epoch,\n",
        "        pct_start=0.0, steps_per_epoch=len(train_loader),\n",
        "        max_lr=CFG.lr, div_factor=25, final_div_factor=4.0e-01\n",
        "    )\n",
        "\n",
        "    loss_func = KLDivLossWithLogits()\n",
        "    loss_func.to(device)\n",
        "    loss_func_val = KLDivLossWithLogitsForVal()\n",
        "\n",
        "    use_amp = CFG.enable_amp\n",
        "    scaler = amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "    best_val_loss = 1.0e+09\n",
        "    best_epoch = 0\n",
        "    train_loss = 0\n",
        "\n",
        "    for epoch in range(1, CFG.max_epoch + 1):\n",
        "        epoch_start = time()\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            batch = to_device(batch, device)\n",
        "            x, t = batch[\"data\"], batch[\"target\"]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with amp.autocast(use_amp):\n",
        "                y = model(x)\n",
        "                loss = loss_func(y, t)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        for batch in val_loader:\n",
        "            x, t = batch[\"data\"], batch[\"target\"]\n",
        "            x = to_device(x, device)\n",
        "            with torch.no_grad(), amp.autocast(use_amp):\n",
        "                y = model(x)\n",
        "            y = y.detach().cpu().to(torch.float32)\n",
        "            loss_func_val(y, t)\n",
        "        val_loss = loss_func_val.compute()\n",
        "        if val_loss < best_val_loss:\n",
        "            best_epoch = epoch\n",
        "            best_val_loss = val_loss\n",
        "            # print(\"save model\")\n",
        "            torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n",
        "\n",
        "        elapsed_time = time() - epoch_start\n",
        "        print(\n",
        "            f\"[epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f}, elapsed_time: {elapsed_time: .3f}\")\n",
        "\n",
        "        if epoch - best_epoch > CFG.es_patience:\n",
        "            print(\"Early Stopping!\")\n",
        "            break\n",
        "\n",
        "        train_loss = 0\n",
        "\n",
        "    return val_fold, best_epoch, best_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "322fb5e3",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "89fef8c1611842da9737a3aa08b0e8d5"
          ]
        },
        "id": "322fb5e3",
        "outputId": "6a5dd47a-94dc-4a31-d561-57379578a5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[fold0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89fef8c1611842da9737a3aa08b0e8d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/87.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[epoch 1] train loss:  0.882599, val loss:  0.851408, elapsed_time:  137.197\n",
            "[epoch 2] train loss:  0.698157, val loss:  0.820204, elapsed_time:  123.991\n",
            "[epoch 3] train loss:  0.608675, val loss:  0.744616, elapsed_time:  123.919\n",
            "[epoch 4] train loss:  0.528086, val loss:  0.753391, elapsed_time:  123.855\n",
            "[epoch 5] train loss:  0.427589, val loss:  0.781515, elapsed_time:  123.798\n",
            "[epoch 6] train loss:  0.318129, val loss:  0.756746, elapsed_time:  123.991\n",
            "[epoch 7] train loss:  0.224556, val loss:  0.803439, elapsed_time:  123.878\n",
            "[epoch 8] train loss:  0.153463, val loss:  0.786738, elapsed_time:  123.963\n",
            "[epoch 9] train loss:  0.116854, val loss:  0.824401, elapsed_time:  124.104\n",
            "Early Stopping!\n",
            "[fold1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[epoch 1] train loss:  0.904280, val loss:  0.938235, elapsed_time:  121.273\n",
            "[epoch 2] train loss:  0.720165, val loss:  0.900330, elapsed_time:  121.473\n",
            "[epoch 3] train loss:  0.638118, val loss:  0.706957, elapsed_time:  121.357\n",
            "[epoch 4] train loss:  0.552333, val loss:  0.737890, elapsed_time:  121.296\n",
            "[epoch 5] train loss:  0.457910, val loss:  0.774971, elapsed_time:  121.153\n",
            "[epoch 6] train loss:  0.350029, val loss:  0.703400, elapsed_time:  121.222\n",
            "[epoch 7] train loss:  0.252007, val loss:  0.714577, elapsed_time:  121.159\n",
            "[epoch 8] train loss:  0.175336, val loss:  0.723147, elapsed_time:  121.460\n",
            "[epoch 9] train loss:  0.132709, val loss:  0.776623, elapsed_time:  121.428\n",
            "[fold2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[epoch 1] train loss:  0.898212, val loss:  0.886630, elapsed_time:  122.120\n",
            "[epoch 2] train loss:  0.710584, val loss:  0.811041, elapsed_time:  121.502\n",
            "[epoch 3] train loss:  0.627898, val loss:  0.830817, elapsed_time:  121.168\n",
            "[epoch 4] train loss:  0.543182, val loss:  0.865721, elapsed_time:  121.211\n",
            "[epoch 5] train loss:  0.456368, val loss:  0.702044, elapsed_time:  121.470\n",
            "[epoch 6] train loss:  0.351186, val loss:  0.767019, elapsed_time:  121.327\n",
            "[epoch 7] train loss:  0.249169, val loss:  0.813521, elapsed_time:  121.270\n",
            "[epoch 8] train loss:  0.169040, val loss:  0.833246, elapsed_time:  121.102\n",
            "[epoch 9] train loss:  0.128260, val loss:  0.853226, elapsed_time:  121.240\n",
            "[fold3]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[epoch 1] train loss:  0.908737, val loss:  0.935427, elapsed_time:  124.594\n",
            "[epoch 2] train loss:  0.706002, val loss:  0.724434, elapsed_time:  124.850\n",
            "[epoch 3] train loss:  0.618819, val loss:  0.730945, elapsed_time:  124.480\n",
            "[epoch 4] train loss:  0.535117, val loss:  0.739224, elapsed_time:  124.769\n",
            "[epoch 5] train loss:  0.452238, val loss:  0.709114, elapsed_time:  124.721\n",
            "[epoch 6] train loss:  0.344210, val loss:  0.767912, elapsed_time:  124.626\n",
            "[epoch 7] train loss:  0.243417, val loss:  0.813730, elapsed_time:  124.590\n",
            "[epoch 8] train loss:  0.166547, val loss:  0.848325, elapsed_time:  124.776\n",
            "[epoch 9] train loss:  0.124330, val loss:  0.883598, elapsed_time:  124.608\n",
            "[fold4]\n",
            "[epoch 1] train loss:  0.892550, val loss:  1.235761, elapsed_time:  126.432\n",
            "[epoch 2] train loss:  0.702810, val loss:  0.771075, elapsed_time:  125.601\n",
            "[epoch 3] train loss:  0.614388, val loss:  0.837626, elapsed_time:  125.151\n",
            "[epoch 4] train loss:  0.535080, val loss:  0.723097, elapsed_time:  125.355\n",
            "[epoch 5] train loss:  0.438436, val loss:  0.857026, elapsed_time:  125.273\n",
            "[epoch 6] train loss:  0.325680, val loss:  0.809226, elapsed_time:  125.411\n",
            "[epoch 7] train loss:  0.229884, val loss:  0.833756, elapsed_time:  125.169\n",
            "[epoch 8] train loss:  0.162821, val loss:  0.863633, elapsed_time:  125.436\n",
            "[epoch 9] train loss:  0.121084, val loss:  0.889576, elapsed_time:  125.217\n"
          ]
        }
      ],
      "source": [
        "# The model is trained over 9 epochs, using a batch size of 32, and the validation results are used to tune the model for improved performance.\n",
        "score_list = []\n",
        "for fold_id in FOLDS:\n",
        "    output_path = Path(f\"fold{fold_id}\")\n",
        "    output_path.mkdir(exist_ok=True)\n",
        "    print(f\"[fold{fold_id}]\")\n",
        "    score_list.append(train_one_fold(CFG, fold_id, train, output_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b50890",
      "metadata": {
        "id": "88b50890"
      },
      "outputs": [],
      "source": [
        "best_log_list = []\n",
        "for (fold_id, best_epoch, _) in score_list:\n",
        "\n",
        "    exp_dir_path = Path(f\"fold{fold_id}\")\n",
        "    oof_pred_arr = {}\n",
        "    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n",
        "    copy_to = f\"./best_model_fold{fold_id}.pth\"\n",
        "    shutil.copy(best_model_path, copy_to)\n",
        "\n",
        "    for p in exp_dir_path.glob(\"*.pth\"):\n",
        "        p.unlink()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581f137a",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "581f137a",
        "outputId": "1ccd2325-2bae-4f42-eb33-85d97d7d4df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV Score KL-Div for ResNet34d 0.807760646315781\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/kaggle/input/kaggle-kl-div')\n",
        "from kaggle_kl_div import score\n",
        "\n",
        "true = train[[\"label_id\"] + CLASSES].copy()\n",
        "\n",
        "oof = pd.DataFrame(oof_pred_arr, columns=CLASSES)\n",
        "oof.insert(0, \"label_id\", train[\"label_id\"])\n",
        "\n",
        "cv_score = score(solution=true, submission=oof, row_id_column_name='label_id')\n",
        "print('CV Score KL-Div for ResNet34d',cv_score)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 7469972,
          "sourceId": 59093,
          "sourceType": "competition"
        },
        {
          "datasetId": 4297749,
          "sourceId": 7392733,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30636,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 6153.848185,
      "end_time": "2024-01-15T09:43:30.680376",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-01-15T08:00:56.832191",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}